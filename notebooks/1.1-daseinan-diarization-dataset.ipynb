{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Workflow Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = 'mix_0000001.wav'\n",
    "wav_data = librosa.load(path=wav_path, sr=8000)\n",
    "if len(wav_data) == 2:\n",
    "    wav_data = wav_data[0]\n",
    "    \n",
    "print(\"wav_data_length   = {} points\".format(len(wav_data)))\n",
    "print(\"wav_data_second   = {:.2f} s\".format(float(len(wav_data) / 8000.)))\n",
    "sample_rate = 8000\n",
    "frame_size = 200\n",
    "frame_shift = 80\n",
    "sub_sampling = 10\n",
    "fft_size = 1 << (frame_size - 1).bit_length()\n",
    "data_len = int(len(wav_data) / frame_shift)\n",
    "data_len = int(data_len / sub_sampling)\n",
    "chunk_size_frame = 500\n",
    "chunk_size_second = int(chunk_size_frame * sub_sampling * frame_shift / sample_rate)\n",
    "print(\"\\\n",
    "sample_rate       = {}\\n\\\n",
    "frame_size        = {}\\n\\\n",
    "frame_shift       = {}\\n\\\n",
    "fft_size          = {}\\n\\\n",
    "sub_sampling      = {}\\n\\\n",
    "data_len          = {} frames\\n\\\n",
    "chunk_size_frame  = {} frames\\n\\\n",
    "chunk_size_second = {} s\\n\\\n",
    "chunk_size_second = chunk_size_frame * sub_sampling * frame_shift / sample_rate\"\n",
    "    .format(sample_rate, frame_size, frame_shift, fft_size, sub_sampling, \n",
    "            data_len, chunk_size_frame, chunk_size_second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _count_frames(data_len, chunk_size, chunk_step):\n",
    "    return int((data_len - chunk_size + chunk_step) / chunk_step)\n",
    "\n",
    "def _gen_frame_indices(data_len, chunk_size, chunk_step):\n",
    "    i = -1\n",
    "    frames_count = _count_frames(data_len, chunk_size, chunk_step)\n",
    "    print(\"chunk count   = {}\".format(frames_count + 1))\n",
    "    \n",
    "    for i in range(frames_count):\n",
    "        yield i * chunk_size, i * chunk_size + chunk_step\n",
    "        \n",
    "    if  i * chunk_size + chunk_step < data_len:\n",
    "        if data_len - (i + 1) * chunk_step > 0:\n",
    "            if i == -1:\n",
    "                yield (i + 1) * chunk_step, data_len\n",
    "            else:\n",
    "                yield data_len - chunk_size, data_len\n",
    "\n",
    "chunk_indices = []\n",
    "for start_time, end_time in _gen_frame_indices(data_len, chunk_size=chunk_size_frame, chunk_step=chunk_size_frame):\n",
    "    chunk_indices.append((start_time * sub_sampling, end_time * sub_sampling))\n",
    "print(\"chunk indices = {}\".format(chunk_indices))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_speakers = 2\n",
    "start_time, end_time = chunk_indices[0]\n",
    "chunk_data = wav_data[start_time * frame_shift: end_time * frame_shift]\n",
    "print(\"start_chunk_index = {}\".format(start_time))\n",
    "print(\"end_chunk_index   = {}\".format(end_time))\n",
    "print(\"start_time        = start_chunk_index * frame_shift = {}\".format(start_time * frame_shift))\n",
    "print(\"end_time          = end_chunk_index   * frame_shift = {}\".format(end_time * frame_shift))\n",
    "print(\"chunk_data length = {}\".format(len(chunk_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(\n",
    "        data,\n",
    "        frame_size=1024,\n",
    "        frame_shift=256):\n",
    "    \"\"\" Compute STFT features\n",
    "\n",
    "    Args:\n",
    "        data: audio signal\n",
    "            (n_samples,)-shaped np.float32 array\n",
    "        frame_size: number of samples in a frame (must be a power of two)\n",
    "        frame_shift: number of samples between frames\n",
    "\n",
    "    Returns:\n",
    "        stft: STFT frames\n",
    "            (n_frames, n_bins)-shaped np.complex64 array\n",
    "    \"\"\"\n",
    "    # round up to nearest power of 2\n",
    "    fft_size = 1 << (frame_size - 1).bit_length()\n",
    "    # HACK: The last frame is ommited\n",
    "    #       as librosa.stft produces such an excessive frame\n",
    "    if len(data) % frame_shift == 0:\n",
    "        return librosa.stft(data, n_fft=fft_size, win_length=frame_size,\n",
    "                            hop_length=frame_shift).T[:-1]\n",
    "    else:\n",
    "        return librosa.stft(data, n_fft=fft_size, win_length=frame_size,\n",
    "                            hop_length=frame_shift).T\n",
    "        \n",
    "Y = stft(data=chunk_data, frame_size=frame_size, frame_shift=frame_shift)\n",
    "\n",
    "print(\"\\\n",
    "chunk_data length = {}\\n\\\n",
    "frame_size        = {}\\n\\\n",
    "frame_shift       = {}\\n\\\n",
    "fft_size          = {}\\n\\\n",
    "Y.shape           = {}\\n\\\n",
    "Y.shape[0](Time)  = chunk_data_len/frame_shift\\n\\\n",
    "Y.shape[1](Freq)  = 1 + fft_size/2\"\n",
    ".format(len(chunk_data), frame_size, frame_shift, fft_size, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.zeros((Y.shape[0], num_speakers), dtype=np.int32).astype(np.float32)\n",
    "print(\"T.shape              = {}\".format(T.shape))\n",
    "print(\"T.shape[0](Time)     = Y.shape[0]\")\n",
    "print(\"T.shape[1](num_spks) = num_speakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(\n",
    "        Y,\n",
    "        transform_type=None,\n",
    "        dtype=np.float32):\n",
    "    \"\"\" Transform STFT feature\n",
    "\n",
    "    Args:\n",
    "        Y: STFT\n",
    "            (n_frames, n_bins)-shaped np.complex array\n",
    "        transform_type:\n",
    "            None, \"log\"\n",
    "        dtype: output data type\n",
    "            np.float32 is expected\n",
    "    Returns:\n",
    "        Y (numpy.array): transformed feature\n",
    "    \"\"\"\n",
    "    Y = np.abs(Y)\n",
    "    if not transform_type:\n",
    "        pass\n",
    "    elif transform_type == 'log':\n",
    "        Y = np.log(np.maximum(Y, 1e-10))\n",
    "    elif transform_type == 'logmel':\n",
    "        n_fft = 2 * (Y.shape[1] - 1)\n",
    "        sr = 16000\n",
    "        n_mels = 40\n",
    "        mel_basis = librosa.filters.mel(sr, n_fft, n_mels)\n",
    "        Y = np.dot(Y ** 2, mel_basis.T)\n",
    "        Y = np.log10(np.maximum(Y, 1e-10))\n",
    "    elif transform_type == 'logmel23':\n",
    "        n_fft = 2 * (Y.shape[1] - 1)\n",
    "        sr = 8000\n",
    "        n_mels = 23\n",
    "        mel_basis = librosa.filters.mel(sr, n_fft, n_mels)\n",
    "        Y = np.dot(Y ** 2, mel_basis.T)\n",
    "        Y = np.log10(np.maximum(Y, 1e-10))\n",
    "    elif transform_type == 'logmel23_mn':\n",
    "        n_fft = 2 * (Y.shape[1] - 1)\n",
    "        sr = 8000\n",
    "        n_mels = 23\n",
    "        mel_basis = librosa.filters.mel(sr, n_fft, n_mels)\n",
    "        Y = np.dot(Y ** 2, mel_basis.T)\n",
    "        Y = np.log10(np.maximum(Y, 1e-10))\n",
    "        mean = np.mean(Y, axis=0)\n",
    "        Y = Y - mean\n",
    "    elif transform_type == 'logmel23_swn':\n",
    "        n_fft = 2 * (Y.shape[1] - 1)\n",
    "        sr = 8000\n",
    "        n_mels = 23\n",
    "        mel_basis = librosa.filters.mel(sr, n_fft, n_mels)\n",
    "        Y = np.dot(Y ** 2, mel_basis.T)\n",
    "        Y = np.log10(np.maximum(Y, 1e-10))\n",
    "        # b = np.ones(300)/300\n",
    "        # mean = scipy.signal.convolve2d(Y, b[:, None], mode='same')\n",
    "\n",
    "        #  simple 2-means based threshoding for mean calculation\n",
    "        powers = np.sum(Y, axis=1)\n",
    "        th = (np.max(powers) + np.min(powers)) / 2.0\n",
    "        for i in range(10):\n",
    "            th = (np.mean(powers[powers >= th]) + np.mean(powers[powers < th])) / 2\n",
    "        mean = np.mean(Y[powers > th, :], axis=0)\n",
    "        Y = Y - mean\n",
    "    elif transform_type == 'logmel23_mvn':\n",
    "        n_fft = 2 * (Y.shape[1] - 1)\n",
    "        sr = 8000\n",
    "        n_mels = 23\n",
    "        mel_basis = librosa.filters.mel(sr, n_fft, n_mels)\n",
    "        Y = np.dot(Y ** 2, mel_basis.T)\n",
    "        Y = np.log10(np.maximum(Y, 1e-10))\n",
    "        mean = np.mean(Y, axis=0)\n",
    "        Y = Y - mean\n",
    "        std = np.maximum(np.std(Y, axis=0), 1e-10)\n",
    "        Y = Y / std\n",
    "    else:\n",
    "        raise ValueError('Unknown transform_type: %s' % transform_type)\n",
    "    return Y.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = transform(Y=Y, transform_type=\"logmel23_mn\")\n",
    "print(\"Y.shape                         = {}\".format(Y.shape))\n",
    "print(\"Y.shape[0](Time)                = before Y.shape[0]\")\n",
    "print(\"Y.shape[1](Log-Mel Filterbank)  = 23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splice(Y, context_size=0):\n",
    "    \"\"\" Frame splicing\n",
    "\n",
    "    Args:\n",
    "        Y: feature\n",
    "            (n_frames, n_featdim)-shaped numpy array\n",
    "        context_size:\n",
    "            number of frames concatenated on left-side\n",
    "            if context_size = 5, 11 frames are concatenated.\n",
    "\n",
    "    Returns:\n",
    "        Y_spliced: spliced feature\n",
    "            (n_frames, n_featdim * (2 * context_size + 1))-shaped\n",
    "    \"\"\"\n",
    "    Y_pad = np.pad(\n",
    "        Y,\n",
    "        [(context_size, context_size), (0, 0)],\n",
    "        'constant')\n",
    "    Y_spliced = np.lib.stride_tricks.as_strided(\n",
    "        np.ascontiguousarray(Y_pad),\n",
    "        (Y.shape[0], Y.shape[1] * (2 * context_size + 1)),\n",
    "        (Y.itemsize * Y.shape[1], Y.itemsize), writeable=False)\n",
    "    return Y_spliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 7\n",
    "Y_spliced = splice(Y=Y, context_size=context_size)\n",
    "print(\"context_size                        = {}\".format(context_size))\n",
    "print(\"Y_spliced.shape                     = {}\".format(Y.shape))\n",
    "print(\"Y_spliced.shape[0](Time)            = Y.shape[0]\")\n",
    "print(\"Y_spliced.shape[1](append context)  = Y.shape[1] * (2 * context_size + 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(Y, T, subsampling=1):\n",
    "    \"\"\" Frame subsampling\n",
    "    \"\"\"\n",
    "    Y_ss = Y[::subsampling]\n",
    "    T_ss = T[::subsampling]\n",
    "    return Y_ss, T_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ss, T_ss = subsample(Y=Y_spliced, T=T, subsampling=sub_sampling)\n",
    "print(\"sub sampling                   = {}\".format(sub_sampling))\n",
    "print(\"Y_ss.shape                     = {}\".format(Y_ss.shape))\n",
    "print(\"Y_ss.shape[0](Time)            = Y_spliced.shape[0] / sub_sampling\")\n",
    "print(\"Y_ss.shape[1](append context)  = Y_spliced.shape[1]\")\n",
    "\n",
    "print(\"T_ss.shape                     = {}\".format(T_ss.shape))\n",
    "print(\"T_ss.shape[0](Time)            = T.shape[0] / sub_sampling\")\n",
    "print(\"T_ss.shape[1](append context)  = T.shape[1]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dasein/Projects/Speech-Diarization')\n",
    "\n",
    "from src.datamodules.components.diarization_dataset import DiarizationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/home/dasein/Projects/Speech-Diarization/data/simu/dev_clean_ns2_beta2_500'\n",
    "dataset = DiarizationDataset(data_dir=data_dir,\n",
    "                             chunk_size=2000,\n",
    "                             context_size=7,\n",
    "                             frame_size=1024,\n",
    "                             frame_shift=256,\n",
    "                             subsampling=10,\n",
    "                             sample_rate=8000,\n",
    "                             input_transform=\"logmel23_mn\",\n",
    "                             n_speakers=None)\n",
    "\n",
    "print(\"dataset length={}\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ss, T_ss = dataset[0]\n",
    "print(\"Y_ss\", type(Y_ss), Y_ss.shape)\n",
    "print(\"T_ss\", type(T_ss), T_ss.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc151fd16db9b51e0a5384d3d4cd420e8b7fffa33a680ea423fdaa6eedf4e1b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('diarization')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
