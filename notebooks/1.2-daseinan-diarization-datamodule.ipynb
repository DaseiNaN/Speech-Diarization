{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dasein/Projects/Speech-Diarization')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Tuple, Optional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from src.datamodules.components.diarization_dataset import DiarizationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    ys, ts, ilens = list(zip(*batch))\n",
    "    ilens = np.array(ilens)\n",
    "    ys = np.array([\n",
    "            np.pad(y,\n",
    "                   [(0, np.max(ilens) - len(y)), (0, 0)],\n",
    "                   'constant',\n",
    "                   constant_values=(-1,)\n",
    "                   ) for y in ys\n",
    "            ])\n",
    "    ts = np.array([\n",
    "            np.pad(t,\n",
    "                   [(0, np.max(ilens) - len(t)), (0, 0)],\n",
    "                   'constant',\n",
    "                   constant_values=(+1,)\n",
    "                   ) for t in ts\n",
    "            ])\n",
    "    ys = torch.from_numpy(np.array(ys)).to(torch.float32)\n",
    "    ts = torch.from_numpy(np.array(ts)).to(torch.float32)\n",
    "    ilens = torch.from_numpy(np.array(ilens)).to(torch.int32)\n",
    "    return ys, ts, ilens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiarizationDataModule(LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 data_dirs: Tuple[str, str, str],\n",
    "                 chunk_size: int = 2000,\n",
    "                 context_size: int = 7,\n",
    "                 frame_size: int = 1024,\n",
    "                 frame_shift: int = 256,\n",
    "                 subsampling: int = 10,\n",
    "                 sample_rate: int = 8000,\n",
    "                 input_transform: str = \"logmel23_mn\",\n",
    "                 n_speakers: int = None,\n",
    "                 batch_sizes: Tuple[int, int, int] = (64, 64, 1),\n",
    "                 num_workers: int = 0\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        \n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "        self.in_size: int = None\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "    \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.\n",
    "\n",
    "        This method is called by lightning when doing `trainer.fit()` and `trainer.test()`,\n",
    "        so be careful not to execute the random split twice! The `stage` can be used to\n",
    "        differentiate whether it's called before trainer.fit()` or `trainer.test()`.\n",
    "        \"\"\"\n",
    "        if not self.data_train and not self.data_val and not self.data_test:\n",
    "            train_dir, val_dir, test_dir = self.hparams.data_dirs\n",
    "            self.data_train = DiarizationDataset(data_dir=train_dir,\n",
    "                                                 chunk_size=self.hparams.chunk_size,\n",
    "                                                 context_size=self.hparams.context_size,\n",
    "                                                 frame_size=self.hparams.frame_size,\n",
    "                                                 frame_shift=self.hparams.frame_shift,\n",
    "                                                 subsampling=self.hparams.subsampling,\n",
    "                                                 sample_rate=self.hparams.sample_rate,\n",
    "                                                 input_transform=self.hparams.input_transform,\n",
    "                                                 n_speakers=self.hparams.n_speakers)\n",
    "            Y, T, ilens = next(iter(self.data_train))\n",
    "            self.in_size = Y.shape[1]\n",
    "            self.data_val = DiarizationDataset(data_dir=val_dir,\n",
    "                                               chunk_size=self.hparams.chunk_size,\n",
    "                                               context_size=self.hparams.context_size,\n",
    "                                               frame_size=self.hparams.frame_size,\n",
    "                                               frame_shift=self.hparams.frame_shift,\n",
    "                                               subsampling=self.hparams.subsampling,\n",
    "                                               sample_rate=self.hparams.sample_rate,\n",
    "                                               input_transform=self.hparams.input_transform,\n",
    "                                               n_speakers=self.hparams.n_speakers)\n",
    "            self.data_test = DiarizationDataset(data_dir=test_dir,\n",
    "                                                chunk_size=self.hparams.chunk_size,\n",
    "                                                context_size=self.hparams.context_size,\n",
    "                                                frame_size=self.hparams.frame_size,\n",
    "                                                frame_shift=self.hparams.frame_shift,\n",
    "                                                subsampling=self.hparams.subsampling,\n",
    "                                                sample_rate=self.hparams.sample_rate,\n",
    "                                                input_transform=self.hparams.input_transform,\n",
    "                                                n_speakers=self.hparams.n_speakers)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_size=self.hparams.batch_sizes[0],\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate_fn\n",
    "            )\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.hparams.batch_sizes[1],\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn\n",
    "            )\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.hparams.batch_sizes[2],\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            shuffle=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = '/home/dasein/Projects/Speech-Diarization/data/'\n",
    "train_dir = os.path.join(data_root_dir, 'simu', 'train_clean_100_ns2_beta2_50000')\n",
    "val_dir = os.path.join(data_root_dir, 'simu', 'dev_clean_ns2_beta2_500')\n",
    "test_dir = os.path.join(data_root_dir, 'callhome', 'callhome1_spk2')\n",
    "\n",
    "data_dir_tuple = (train_dir, val_dir, test_dir)\n",
    "print(data_dir_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = DiarizationDataModule(data_dirs=data_dir_tuple)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = datamodule.train_dataloader()\n",
    "for Y, T, ilens in train_dataloader:\n",
    "    print(Y.shape, type(Y))\n",
    "    print(T.shape, type(T))\n",
    "    print(ilens.shape, type(ilens))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.in_size"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2452e518d09b2267378e6914cf9981888d6ae5f230e9e0da64b34b6c652eb68b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('SDenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
